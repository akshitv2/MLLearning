{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "iVc67fe7exSn"
      },
      "id": "iVc67fe7exSn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "UD-CsCDrfPge"
      },
      "id": "UD-CsCDrfPge",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Google's pretrained Word2Vec model (300-dimensional vectors)\n",
        "print(\"Loading Word2Vec model...\")\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "print(\"Model loaded!\")\n",
        "\n",
        "# Example labeled sentences for classification\n",
        "sentences = [\n",
        "    (\"I love this movie, it's fantastic!\", \"positive\"),\n",
        "    (\"This restaurant has amazing food.\", \"positive\"),\n",
        "    (\"The weather is terrible today.\", \"negative\"),\n",
        "    (\"I hate being stuck in traffic.\", \"negative\"),\n",
        "    (\"This phone has great battery life.\", \"positive\"),\n",
        "    (\"The service at the hotel was awful.\", \"negative\"),\n",
        "]\n",
        "\n",
        "# Function to convert a sentence into a vector by averaging word embeddings\n",
        "def sentence_to_vector(sentence, model):\n",
        "    words = sentence.lower().split()  # Tokenize sentence\n",
        "    word_vectors = [model[word] for word in words if word in model]  # Get word embeddings\n",
        "    if len(word_vectors) == 0:\n",
        "        return np.zeros(300)  # Return zero vector if no known words are found\n",
        "    return np.mean(word_vectors, axis=0)  # Average word vectors\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([sentence_to_vector(text, model) for text, label in sentences])\n",
        "y = np.array([label for text, label in sentences])\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)  # Convert \"positive\"/\"negative\" to 0/1\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a simple classifier (Logistic Regression)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = classifier.score(X_test, y_test)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Test the model with a new sentence\n",
        "test_sentence = \"I really enjoyed this book!\"\n",
        "vector = sentence_to_vector(test_sentence, model)\n",
        "prediction = classifier.predict([vector])[0]\n",
        "print(f\"Sentence: '{test_sentence}' â†’ Predicted Sentiment: {encoder.inverse_transform([prediction])[0]}\")\n"
      ],
      "metadata": {
        "id": "58KSK259ey4p"
      },
      "id": "58KSK259ey4p",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}