{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f62ed4-fe6a-448f-827d-51b470e77a7d",
      "metadata": {
        "id": "41f62ed4-fe6a-448f-827d-51b470e77a7d",
        "outputId": "fb31864d-e4ad-4807-c288-07c0b1a53da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.6.0\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
        "tf.config.run_functions_eagerly(True)  # Ensure eager execution is enabled\n",
        "# import tensorflow as tf\n",
        "\n",
        "# Enable eager execution for tf.data functions\n",
        "tf.data.experimental.enable_debug_mode()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "umUpTcCkBJUz",
        "outputId": "08d314eb-3429-4675-ade8-3cbf4d46dd29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "umUpTcCkBJUz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eaab9a6-1c01-4808-a053-ff3b303b39d3",
      "metadata": {
        "id": "5eaab9a6-1c01-4808-a053-ff3b303b39d3"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "import sys\n",
        "import copy\n",
        "import requests\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b864ee62-d775-46a2-af6b-0385ae59e900",
      "metadata": {
        "id": "b864ee62-d775-46a2-af6b-0385ae59e900"
      },
      "outputs": [],
      "source": [
        "def extract_zip(zip_path, dest_dir, overwrite=False):\n",
        "    if not os.path.exists(zip_path):\n",
        "        raise FileNotFoundError(f\"ZIP file not found: {zip_path}\")\n",
        "\n",
        "    # Ensure destination directory exists\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        if overwrite:\n",
        "            # Remove existing files in destination if they exist\n",
        "            for file in zip_ref.namelist():\n",
        "                file_path = os.path.join(dest_dir, file)\n",
        "                if os.path.exists(file_path):\n",
        "                    if os.path.isdir(file_path):\n",
        "                        shutil.rmtree(file_path)\n",
        "                    else:\n",
        "                        os.remove(file_path)\n",
        "        zip_ref.extractall(dest_dir)\n",
        "        print(f\"Extracted '{zip_path}' to '{dest_dir}'\")\n",
        "\n",
        "def extract_images_label_by_folder(zip_path, dest_dir, image_size=(224, 224),overwrite=False, zip_subdirectory = \"\",batch_size=32):\n",
        "    extract_zip(zip_path, dest_dir, overwrite=False)\n",
        "    train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "            dest_dir + \"/dataset\",\n",
        "            labels=\"inferred\",\n",
        "            label_mode=\"int\",\n",
        "            class_names=None,\n",
        "            color_mode='rgb',\n",
        "            image_size=(224, 224),\n",
        "            interpolation=\"nearest\",\n",
        "            batch_size=batch_size,\n",
        "            validation_split=0.2,\n",
        "            subset=\"training\",\n",
        "            seed=123)\n",
        "\n",
        "    test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "            dest_dir + \"/dataset\",\n",
        "            labels=\"inferred\",\n",
        "            label_mode=\"int\",\n",
        "            class_names=None,\n",
        "            interpolation=\"nearest\",\n",
        "            color_mode='rgb',\n",
        "            image_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            validation_split=0.2,\n",
        "            subset=\"validation\",\n",
        "            seed=123)\n",
        "    return train_dataset,test_dataset\n",
        "def get_class_distribution(dataset):\n",
        "    class_counts = {}\n",
        "    for label in range(len(dataset.class_names)):\n",
        "        class_counts[label] = 0\n",
        "    for image, label in dataset.unbatch():\n",
        "        class_counts[label.numpy()]+=1\n",
        "    return class_counts\n",
        "\n",
        "def plot_class_distribution(class_counts):\n",
        "    sorted_class_counts = dict(sorted(class_counts.items(), key=lambda item: class_counts[item[0]], reverse=True))\n",
        "    labels = list(sorted_class_counts.keys())\n",
        "    values = list(sorted_class_counts.values())\n",
        "    plt.figure(figsize=(15, 6))  # Adjust figure size for better readability\n",
        "    plt.bar(labels, values)\n",
        "    plt.xlabel(\"Class Labels\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Class Distribution\")\n",
        "    plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility if needed\n",
        "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "    plt.show()\n",
        "\n",
        "def balance_images_distribution(dataset, class_counts, plot_dist = False, top_p_to_avg = 0.1):\n",
        "\n",
        "    def get_avg_entry_count(top_p_to_avg = 0.1):\n",
        "        sorted_counts = dict(sorted(class_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "        values = list(sorted_counts.values())\n",
        "\n",
        "        top_percent_index = int(len(values) * top_p_to_avg)\n",
        "        top_percent_values = values[:top_percent_index]\n",
        "        average_top_p = np.mean(top_percent_values)\n",
        "        print(f\"Average number of values for top p% entries: {average_top_p}\")\n",
        "        return average_top_p\n",
        "\n",
        "    def augment(image_orig):\n",
        "        image = tf.image.random_flip_left_right(image_orig)\n",
        "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "        image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "        return image\n",
        "\n",
        "    # Function to add an entry\n",
        "    def add_entry(images, labels, image, label):\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    new_images = []\n",
        "    new_labels = []\n",
        "    avg_entry_count = get_avg_entry_count(top_p_to_avg)\n",
        "\n",
        "    while(get_avg_entry_count(0.9) + 1 < avg_entry_count):\n",
        "        for images, labels in dataset.unbatch():\n",
        "            if(class_counts[labels.numpy()] < avg_entry_count):\n",
        "                add_entry(new_images, new_labels,augment(images),labels)\n",
        "                class_counts[labels.numpy()] += 1\n",
        "    if(plot_dist):\n",
        "        plot_class_distribution(class_counts)\n",
        "    return tf.data.Dataset.from_tensor_slices((new_images, new_labels))\n",
        "\n",
        "def one_hot_encode(image, label):\n",
        "  return image, tf.one_hot(label, depth=len(classes))\n",
        "\n",
        "def filter_p_percent(class_dist, p = 0.2):\n",
        "    return (sorted(class_dist.keys(), key = lambda x: class_dist[x], reverse=True))[0:int(len(class_dist.keys())*p)];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a84a1cce-a154-44ea-8918-b6ccaa18ab26",
      "metadata": {
        "id": "a84a1cce-a154-44ea-8918-b6ccaa18ab26",
        "outputId": "32c04cd3-f53c-49f4-80de-d69f45ee7aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 'G:\\Datasets\\Pokemon151to10k.zip' to 'G:\\Temp'\n",
            "Found 10658 files belonging to 149 classes.\n",
            "Using 8527 files for training.\n",
            "Found 10658 files belonging to 149 classes.\n",
            "Using 2131 files for validation.\n"
          ]
        }
      ],
      "source": [
        "zip_file_path = r\"G:\\Datasets\\Pokemon151to10k.zip\" # Replace with actual path\n",
        "destination_directory = r\"G:\\Temp\" #Replace with your temporary directory\n",
        "unencoded_train_dataset,unencoded_test_dataset = extract_images_label_by_folder(zip_file_path, destination_directory, overwrite=False,batch_size=32)\n",
        "classes = unencoded_train_dataset.class_names\n",
        "class_dist = get_class_distribution(unencoded_train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001a65c6-52e5-4f25-b9ec-3aea9a808022",
      "metadata": {
        "id": "001a65c6-52e5-4f25-b9ec-3aea9a808022"
      },
      "outputs": [],
      "source": [
        "train_dataset = unencoded_train_dataset.map(one_hot_encode)\n",
        "test_dataset = unencoded_test_dataset.map(one_hot_encode)\n",
        "# del unencoded_train_dataset\n",
        "# del unencoded_test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4edc600-c62f-4452-b2b2-33b982b48990",
      "metadata": {
        "id": "f4edc600-c62f-4452-b2b2-33b982b48990",
        "outputId": "ac84cdfc-5fc9-4755-b5a2-e472d7dec615"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.uint8, name=None),\n",
              " TensorSpec(shape=(None, 149), dtype=tf.float32, name=None))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "163338d5-a29b-4b5e-be96-67428777b404",
      "metadata": {
        "id": "163338d5-a29b-4b5e-be96-67428777b404"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained VGG16 model without the top classification layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) # Adjust input_shape if needed\n",
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(4096)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = Dense(4096)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "predictions = Dense(149, activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model with a slow learning rate\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-4) # Example: A very slow learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b998c961-8976-4f3e-a52b-116beaae9e58",
      "metadata": {
        "id": "b998c961-8976-4f3e-a52b-116beaae9e58",
        "outputId": "f3282037-c25f-4742-c95c-0e89a6ca094b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "OOM when allocating tensor with shape[32,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1193\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1189\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1190\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1191\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1192\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1193\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1195\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:862\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[0;32m    861\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a training execution with one step.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:852\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    849\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m    851\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 852\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    854\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    855\u001b[0m write_scalar_summaries(outputs, step\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_train_counter)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1282\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1285\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1286\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2847\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2848\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2849\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3631\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:597\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m--> 845\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:802\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Run forward pass.\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backprop\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m--> 802\u001b[0m   y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    803\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(\n\u001b[0;32m    804\u001b[0m       y, y_pred, sample_weight, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1057\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1053\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1057\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1060\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:420\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    403\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m  In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:556\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    553\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 556\u001b[0m outputs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mlayer(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mflat_output_ids, nest\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1057\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1053\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1057\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1060\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:253\u001b[0m, in \u001b[0;36mConv.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_causal:  \u001b[38;5;66;03m# Apply causal padding to inputs for Conv1D.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mpad(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_causal_padding(inputs))\n\u001b[1;32m--> 253\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolution_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[0;32m    256\u001b[0m   output_rank \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1131\u001b[0m, in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnn.convolution\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvolution_v2\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     dilations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1130\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1131\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvolution_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=redefined-builtin\u001b[39;49;00m\n\u001b[0;32m   1133\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1261\u001b[0m, in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1258\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1259\u001b[0m     op \u001b[38;5;241m=\u001b[39m conv1d\n\u001b[1;32m-> 1261\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1270\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m channel_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:2715\u001b[0m, in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2711\u001b[0m input_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m input_rank \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m   2713\u001b[0m   \u001b[38;5;66;03m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[39;00m\n\u001b[0;32m   2714\u001b[0m   \u001b[38;5;66;03m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[39;00m\n\u001b[1;32m-> 2715\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2716\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2717\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2718\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2719\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2720\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2721\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2722\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2723\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m squeeze_batch_dims(\n\u001b[0;32m   2724\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2725\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2732\u001b[0m     inner_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   2733\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:931\u001b[0m, in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 931\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m    933\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32mD:\\Software\\Conda\\envs\\dlCuda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m message \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6940\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6941\u001b[0m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
          ]
        }
      ],
      "source": [
        "model.fit(train_dataset, epochs=10, steps_per_epoch=1, validation_data=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55bcd402-3892-4cfb-b4aa-28bf7eac05ae",
      "metadata": {
        "id": "55bcd402-3892-4cfb-b4aa-28bf7eac05ae"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers[-4:]:  # Unfreezing last 4 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model with a lower learning rate\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train again with some layers unfrozen\n",
        "model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}