{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "id": "pPn5R9-FBmc9"
   },
   "id": "pPn5R9-FBmc9",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DATA_DIR = \"./data\"\n",
    "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\n",
    "LOG_DIR = os.path.join(DATA_DIR, \"logs\")"
   ],
   "metadata": {
    "id": "33y8IEwABwT8"
   },
   "id": "33y8IEwABwT8",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def download_and_read(urls):\n",
    "    texts = []\n",
    "    for i, url in enumerate(urls):\n",
    "        p = tf.keras.utils.get_file(\"ex1-{:d}.txt\".format(i), url, cache_dir=\"..\")\n",
    "        text = open(p, mode=\"r\", encoding=\"utf-8\").read()\n",
    "        # remove byte order mark\n",
    "        text = text.replace(\"\\ufeff\", \"\")\n",
    "        # remove newlines\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = re.sub(r'\\s+', \" \", text)\n",
    "        # add it to the list\n",
    "        texts.extend(text)\n",
    "    return texts\n",
    "\n",
    "def split_train_labels(sequence):\n",
    "    input_seq = sequence[0:-1]\n",
    "    output_seq = sequence[1:]\n",
    "    return input_seq, output_seq\n",
    "\n",
    "class CharGenModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, num_timesteps,\n",
    "            embedding_dim, **kwargs):\n",
    "        super(CharGenModel, self).__init__(**kwargs)\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim\n",
    "        )\n",
    "        self.rnn_layer = tf.keras.layers.GRU(\n",
    "            num_timesteps,\n",
    "            recurrent_initializer=\"glorot_uniform\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            stateful=True,\n",
    "            return_sequences=True\n",
    "        )\n",
    "        self.dense_layer = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.rnn_layer(x)\n",
    "        output = self.dense_layer(x)\n",
    "        return output\n",
    "\n",
    "def loss(labels, predictions):\n",
    "    return tf.losses.sparse_categorical_crossentropy(\n",
    "        labels,\n",
    "        predictions,\n",
    "        from_logits=True\n",
    "    )\n",
    "\n",
    "def generate_text(model, prefix_string, char2idx, idx2char,\n",
    "        num_chars_to_generate=1000, temperature=1.0):\n",
    "    input = [char2idx[s] for s in prefix_string]\n",
    "    input = tf.expand_dims(input, 0)\n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    for i in range(num_chars_to_generate):\n",
    "        preds = model(input)\n",
    "        preds = tf.squeeze(preds, 0) / temperature\n",
    "        # predict char returned by model\n",
    "        pred_id = tf.random.categorical(preds, num_samples=1)[-1, 0].numpy()\n",
    "        text_generated.append(idx2char[pred_id])\n",
    "        # pass the prediction as the next input to the model\n",
    "        input = tf.expand_dims([pred_id], 0)\n",
    "\n",
    "    return prefix_string + \"\".join(text_generated)"
   ],
   "metadata": {
    "id": "xJs4MmVSCCy2"
   },
   "id": "xJs4MmVSCCy2",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "texts = download_and_read([\n",
    "    \"http://www.gutenberg.org/cache/epub/28885/pg28885.txt\",\n",
    "    \"https://www.gutenberg.org/files/12/12-0.txt\"\n",
    "])"
   ],
   "metadata": {
    "id": "JjiDvO1qCnGq"
   },
   "id": "JjiDvO1qCnGq",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vocab = sorted(set(texts))\n",
    "print(\"vocab size: {:d}\".format(len(vocab)))\n",
    "\n",
    "char2idx = {c:i for i, c in enumerate(vocab)}\n",
    "idx2char = {i:c for c, i in char2idx.items()}\n",
    "\n",
    "texts_as_ints = np.array([char2idx[c] for c in texts])\n",
    "data = tf.data.Dataset.from_tensor_slices(texts_as_ints)"
   ],
   "metadata": {
    "id": "mJRFOJfiCquK",
    "outputId": "91b571d4-63a9-40fb-b950-f2050b9421ba",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "mJRFOJfiCquK",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vocab size: 93\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "seq_length = 100\n",
    "sequences = data.batch(seq_length + 1, drop_remainder=True)\n",
    "# Batches the 'data' dataset into sequences of length (seq_length + 1),\n",
    "# dropping any remaining elements that don't fit exactly into a full batch.\n",
    "# Useful for creating input-target pairs for sequence models (like language models),\n",
    "# where the input is seq[:-1] and target is seq[1:].\n",
    "\n",
    "sequences = sequences.map(split_train_labels)"
   ],
   "metadata": {
    "id": "EtiDyk7nC2dq"
   },
   "id": "EtiDyk7nC2dq",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for input_seq, output_seq in sequences.take(3):\n",
    "    print(\"input:[{:s}]\".format(\n",
    "        \"\".join([idx2char[i] for i in input_seq.numpy()])))\n",
    "    print(\"output:[{:s}]\".format(\n",
    "        \"\".join([idx2char[i] for i in output_seq.numpy()])))"
   ],
   "metadata": {
    "id": "8pFU3LReDwR3",
    "outputId": "8ea2ea95-ce6a-448b-e2af-5439e86673f8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "8pFU3LReDwR3",
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input:[The Project Gutenberg eBook of Alice's Adventures in Wonderland This ebook is for the use of anyone ]\n",
      "output:[he Project Gutenberg eBook of Alice's Adventures in Wonderland This ebook is for the use of anyone a]\n",
      "input:[nywhere in the United States and most other parts of the world at no cost and with almost no restric]\n",
      "output:[ywhere in the United States and most other parts of the world at no cost and with almost no restrict]\n",
      "input:[ions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg]\n",
      "output:[ons whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg ]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "steps_per_epoch = len(texts) // seq_length // batch_size\n",
    "dataset = sequences.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "print(dataset)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "\n",
    "model = CharGenModel(vocab_size, seq_length, embedding_dim)\n",
    "model.build(input_shape=(batch_size, seq_length))\n",
    "model.summary()"
   ],
   "metadata": {
    "id": "_JIH1ybQDVPs",
    "outputId": "659d7dd6-8db4-4169-dffd-191f5a2906af",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    }
   },
   "id": "_JIH1ybQDVPs",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'char_gen_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"char_gen_model\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"char_gen_model\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001B[38;5;33mGRU\u001B[0m)                       │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for input_batch, label_batch in dataset.take(1):\n",
    "    pred_batch = model(input_batch)\n",
    "\n",
    "print(pred_batch.shape)\n",
    "assert(pred_batch.shape[0] == batch_size)\n",
    "assert(pred_batch.shape[1] == seq_length)\n",
    "assert(pred_batch.shape[2] == vocab_size)"
   ],
   "metadata": {
    "id": "HoJ2I_F6ENMH",
    "outputId": "b86f2c65-c7e4-4138-e644-3751dd47f021",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "HoJ2I_F6ENMH",
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(64, 100, 93)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(), loss=loss)\n",
    "\n",
    "# we will train our model for 50 epochs, and after every 10 epochs\n",
    "# we want to see how well it will generate text\n",
    "num_epochs = 50\n",
    "for i in range(num_epochs // 10):\n",
    "    model.fit(\n",
    "        dataset.repeat(),\n",
    "        epochs=10,\n",
    "        steps_per_epoch=steps_per_epoch\n",
    "        # callbacks=[checkpoint_callback, tensorboard_callback]\n",
    "    )\n",
    "    checkpoint_file = os.path.join(\n",
    "        CHECKPOINT_DIR, \"model_epoch_{:d}\".format(i+1))\n",
    "    model.save_weights(checkpoint_file)\n",
    "\n",
    "    # create a generative model using the trained model so far\n",
    "    gen_model = CharGenModel(vocab_size, seq_length, embedding_dim)\n",
    "    gen_model.load_weights(checkpoint_file)\n",
    "    gen_model.build(input_shape=(1, seq_length))\n",
    "\n",
    "    print(\"after epoch: {:d}\".format(i+1)*10)\n",
    "    print(generate_text(gen_model, \"Alice \", char2idx, idx2char))\n",
    "    print(\"---\")"
   ],
   "metadata": {
    "id": "MlkWWnKKEOei",
    "outputId": "7aa0de46-79bf-4641-b6d4-d6d43bac1224",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "MlkWWnKKEOei",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m46/51\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m1s\u001B[0m 211ms/step - loss: 3.7391"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
