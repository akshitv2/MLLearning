{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "pPn5R9-FBmc9"
      },
      "id": "pPn5R9-FBmc9",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"./data\"\n",
        "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\n",
        "LOG_DIR = os.path.join(DATA_DIR, \"logs\")"
      ],
      "metadata": {
        "id": "33y8IEwABwT8"
      },
      "id": "33y8IEwABwT8",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_read(urls):\n",
        "    texts = []\n",
        "    for i, url in enumerate(urls):\n",
        "        p = tf.keras.utils.get_file(\"ex1-{:d}.txt\".format(i), url,cache_dir=\".\")\n",
        "        text = open(p, mode=\"r\", encoding=\"utf-8\").read()\n",
        "        # remove byte order mark\n",
        "        text = text.replace(\"\\ufeff\", \"\")\n",
        "        # remove newlines\n",
        "        text = text.replace('\\n', ' ')\n",
        "        text = re.sub(r'\\s+', \" \", text)\n",
        "        # add it to the list\n",
        "        texts.extend(text)\n",
        "    return texts\n",
        "\n",
        "def split_train_labels(sequence):\n",
        "    input_seq = sequence[0:-1]\n",
        "    output_seq = sequence[1:]\n",
        "    return input_seq, output_seq\n",
        "\n",
        "class CharGenModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, num_timesteps,\n",
        "            embedding_dim, **kwargs):\n",
        "        super(CharGenModel, self).__init__(**kwargs)\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim\n",
        "        )\n",
        "        self.rnn_layer = tf.keras.layers.GRU(\n",
        "            num_timesteps,\n",
        "            recurrent_initializer=\"glorot_uniform\",\n",
        "            recurrent_activation=\"sigmoid\",\n",
        "            stateful=True,\n",
        "            return_sequences=True\n",
        "        )\n",
        "        self.dense_layer = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding_layer(inputs)\n",
        "        x = self.rnn_layer(x)\n",
        "        output = self.dense_layer(x)\n",
        "        return output\n",
        "\n",
        "def loss(labels, predictions):\n",
        "    return tf.losses.sparse_categorical_crossentropy(\n",
        "        labels,\n",
        "        predictions,\n",
        "        from_logits=True\n",
        "    )"
      ],
      "metadata": {
        "id": "xJs4MmVSCCy2"
      },
      "id": "xJs4MmVSCCy2",
      "execution_count": 4,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}